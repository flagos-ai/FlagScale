defaults:
  - train: robobrain_x0
  - _self_

experiment:
  exp_name: robobrain_x0
  exp_dir: ./${experiment.exp_name}
  task:
    type: train
    backend: megatron
    entrypoint: ./flagscale/train/train_robobrain_x0.py

  runner:
    backend: torchrun
    nnodes: 1
    nproc_per_node: 4
    rdzv_backend: static
    # hostfile: /share/project/jiyuheng/exp0/hostfile.32
    # ssh_port: 22
  cmds:
    before_start: ulimit -n 1048576 && source /root/miniconda3/bin/activate flagscale-train && export https_proxy=http://10.8.48.6:2080 && export http_proxy=http://10.8.48.6:2080
  envs:
    CUDA_VISIBLE_DEVICES: 4,5,6,7
    CUDA_DEVICE_MAX_CONNECTIONS: 1
    NVTE_APPLY_QK_LAYER_SCALING: 0
    NVTE_ALLOW_NONDETERMINISTIC_ALGO: 0
    NCCL_IB_DISABLE: 0
    # GLOO_SOCKET_IFNAME: eth0
    # NCCL_SOCKET_IFNAME: eth0
    # NCCL_IB_HCA: mlx5_100,mlx5_101,mlx5_102,mlx5_103,mlx5_104,mlx5_105,mlx5_106,mlx5_107
    NCCL_IB_HCA: mlx5_104,mlx5_105,mlx5_106,mlx5_107
    GLOO_SOCKET_IFNAME: ens101
    NCCL_SOCKET_IFNAME: ens101
    NCCL_IB_GID_INDEX: 7
    LIBRARY_PATH: /usr/local/cuda/lib64/stubs
    LD_LIBRARY_PATH: /usr/local/cuda-12.4/lib64:/usr/local/cuda-12.4/lib64:/usr/local/cuda-12.4/lib64:/usr/local/lib:/usr/local/mpi/lib:/usr/local/mpi/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
    PATH: /root/miniconda3/envs/flagscale-train/bin:/root/miniconda3/condabin:/client-tools:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

action: run

hydra:
  run:
    dir: ${experiment.exp_dir}/hydra
