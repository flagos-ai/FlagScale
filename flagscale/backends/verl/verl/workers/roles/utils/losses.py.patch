diff --git a/verl/workers/roles/utils/losses.py b/verl/workers/roles/utils/losses.py
index 3693e5eb..1d68a410 100644
--- a/verl/workers/roles/utils/losses.py
+++ b/verl/workers/roles/utils/losses.py
@@ -13,15 +13,22 @@
 # limitations under the License.
 
 
+import logging
+import os
 import torch
 from tensordict import TensorDict
 
 from verl.trainer.ppo.core_algos import agg_loss, compute_value_loss, get_policy_loss_fn, kl_penalty
 from verl.utils import tensordict_utils as tu
 from verl.utils.dataset.dataset_utils import DatasetPadMode
+from verl.utils.logger import print_rank_0
 from verl.utils.torch_functional import masked_mean
 from verl.workers.config import ActorConfig, CriticConfig
 from verl.workers.roles.utils.padding import no_padding_2_padding
+from megatron.core.packed_seq_params import PackedSeqParams
+
+logger = logging.getLogger(__file__)
+logger.setLevel(os.getenv("VERL_LOGGING_LEVEL", "WARN"))
 
 
 def sft_loss(config: ActorConfig, model_output, data: TensorDict, dp_group=None):
@@ -53,7 +60,247 @@ def ppo_loss(config: ActorConfig, model_output, data: TensorDict, dp_group=None)
     log_prob = model_output["log_probs"]
     entropy = model_output.get("entropy", None)
 
+    seqpack_loss_enabled = config.policy_loss.get("seqpack_loss", False) if hasattr(config, "policy_loss") and config.policy_loss else False
+    
+    # Get rank info for logging
+    try:
+        global_rank = torch.distributed.get_rank() if torch.distributed.is_initialized() else -1
+    except Exception:
+        global_rank = -1
+    
+    if seqpack_loss_enabled:
+        packed_seq_params = tu.get_non_tensor_data(data, key="packed_seq_params", default=None)
+        has_packed_seq_params = packed_seq_params is not None
+        has_nested_tensor = hasattr(log_prob, "is_nested") and log_prob.is_nested
+        has_packed_seq_params_class = PackedSeqParams is not None
+        
+        if has_packed_seq_params and has_nested_tensor and has_packed_seq_params_class:
+            msg = f"[PPO Loss] Using seqpack_loss mode (rank={global_rank}): seqpack_loss=True, packed_seq_params={has_packed_seq_params}, is_nested={has_nested_tensor}"
+            logger.warning(msg)
+            print_rank_0(msg)
+            return _ppo_loss_with_sequence_packing(
+                config, model_output, data, dp_group, packed_seq_params
+            )
+        else:
+            msg = f"[PPO Loss] Warning: seqpack_loss=True but conditions not met (rank={global_rank}): packed_seq_params={has_packed_seq_params}, is_nested={has_nested_tensor}, PackedSeqParams={has_packed_seq_params_class}. Falling back to standard loss."
+            logger.warning(msg)
+            print_rank_0(msg)
+            return _ppo_loss_standard(
+                config, model_output, data, dp_group
+            )
+    else:
+        # Use standard loss computation
+        msg = f"[PPO Loss] Using standard_loss mode (rank={global_rank}): seqpack_loss=False or not set"
+        logger.warning(msg)
+        print_rank_0(msg)
+        return _ppo_loss_standard(
+            config, model_output, data, dp_group
+        )
+
+
+def value_loss(config: CriticConfig, model_output, data: TensorDict, dp_group=None):
+    vpreds = model_output["values"]
+    seqpack_loss_enabled = False
+    
+    # Get rank info for logging
+    try:
+        global_rank = torch.distributed.get_rank() if torch.distributed.is_initialized() else -1
+    except Exception:
+        global_rank = -1
+    
+    if hasattr(config, "seqpack_loss"):
+        seqpack_loss_enabled = config.seqpack_loss
+    elif hasattr(config, "policy_loss") and config.policy_loss:
+        if isinstance(config.policy_loss, dict):
+            seqpack_loss_enabled = config.policy_loss.get("seqpack_loss", False)
+        elif hasattr(config.policy_loss, "seqpack_loss"):
+            seqpack_loss_enabled = config.policy_loss.seqpack_loss
+    
+    if not seqpack_loss_enabled:
+        packed_seq_params = tu.get_non_tensor_data(data, key="packed_seq_params", default=None)
+        if packed_seq_params is not None and hasattr(vpreds, "is_nested") and vpreds.is_nested:
+            seqpack_loss_enabled = True
+            msg = f"[Value Loss] Auto-detected sequence packing format, enabling seqpack_loss (rank={global_rank})"
+            logger.warning(msg)
+            print_rank_0(msg)
+    
+    if seqpack_loss_enabled:
+        packed_seq_params = tu.get_non_tensor_data(data, key="packed_seq_params", default=None)
+        has_packed_seq_params = packed_seq_params is not None
+        has_nested_tensor = hasattr(vpreds, "is_nested") and vpreds.is_nested
+        has_packed_seq_params_class = PackedSeqParams is not None
+        
+        if has_packed_seq_params and has_nested_tensor and has_packed_seq_params_class:
+            msg = f"[Value Loss] Using seqpack_loss mode (rank={global_rank}): seqpack_loss=True, packed_seq_params={has_packed_seq_params}, is_nested={has_nested_tensor}"
+            logger.warning(msg)
+            print_rank_0(msg)
+            return _value_loss_with_sequence_packing(
+                config, model_output, data, dp_group, packed_seq_params
+            )
+        else:
+            msg = f"[Value Loss] Warning: seqpack_loss=True but conditions not met (rank={global_rank}): packed_seq_params={has_packed_seq_params}, is_nested={has_nested_tensor}, PackedSeqParams={has_packed_seq_params_class}. Falling back to standard loss."
+            logger.warning(msg)
+            print_rank_0(msg)
+            return _value_loss_standard(config, model_output, data, dp_group)
+    else:
+        # Use standard loss computation
+        msg = f"[Value Loss] Using standard_loss mode (rank={global_rank}): seqpack_loss=False or not set"
+        logger.warning(msg)
+        print_rank_0(msg)
+        return _value_loss_standard(config, model_output, data, dp_group)
+
+
+def _value_loss_standard(config: CriticConfig, model_output, data: TensorDict, dp_group=None):
+    """Standard value loss computation without sequence packing."""
+    # Get rank info for logging
+    try:
+        global_rank = torch.distributed.get_rank() if torch.distributed.is_initialized() else -1
+    except Exception:
+        global_rank = -1
+    
+    vpreds = model_output["values"]
+    vpreds = no_padding_2_padding(vpreds, data)  # (bsz, response_length)
+
+    values = data["values"]
+    returns = data["returns"]
+    response_mask = data["response_mask"].to(bool)
+
+    vf_loss, vf_clipfrac = compute_value_loss(
+        vpreds=vpreds,
+        values=values,
+        returns=returns,
+        response_mask=response_mask,
+        cliprange_value=config.cliprange_value,
+        loss_agg_mode=config.loss_agg_mode,
+    )
+
+    metrics = {}
+
+    metrics.update(
+        {
+            "critic/vf_loss": vf_loss.detach().item(),
+            "critic/vf_clipfrac": vf_clipfrac.detach().item(),
+            "critic/vpred_mean": masked_mean(vpreds, response_mask).detach().item(),
+        }
+    )
+
+    return vf_loss, metrics
+
+
+def _value_loss_with_sequence_packing(config: CriticConfig, model_output, data: TensorDict, dp_group=None, packed_seq_params=None):
+    """
+    Compute value loss with sequence packing support.
+    This function processes each sequence individually to avoid padding effects.
+    
+    Args:
+        config: CriticConfig
+        model_output: Dict containing "values" (nested tensor)
+        data: TensorDict containing values, returns, response_mask, etc.
+        dp_group: Data parallel group (optional)
+        packed_seq_params: PackedSeqParams object containing sequence boundary information
+    
+    Returns:
+        vf_loss: Accumulated value loss across all sequences
+        metrics: Accumulated metrics dictionary
+    """
+    vpreds = model_output["values"]
+    
+    # Get rank info for logging
+    try:
+        global_rank = torch.distributed.get_rank() if torch.distributed.is_initialized() else -1
+    except Exception:
+        global_rank = -1
+    
+    # Check if vpreds is a nested tensor
+    if not (hasattr(vpreds, "is_nested") and vpreds.is_nested):
+        # If not nested tensor, fall back to standard loss
+        msg = f"[Value Loss] Warning: vpreds is not a nested tensor, falling back to standard loss (rank={global_rank})"
+        logger.warning(msg)
+        print_rank_0(msg)
+        return _value_loss_standard(config, model_output, data, dp_group)
+    
+    # Get sequence boundaries from nested tensor
+    vpreds_offsets = vpreds.offsets()  # cu_seqlens
+    vpreds_values = vpreds.values()    # [total_tokens]
+    num_sequences = len(vpreds_offsets) - 1
+    
+    loss_accum = 0.0
+    metrics_accum = {}
+
+    # Process each sequence individually
+    for seq_idx in range(num_sequences):
+        # Get vpreds for current sequence
+        seq_vpreds_start = vpreds_offsets[seq_idx].item()
+        seq_vpreds_end = vpreds_offsets[seq_idx + 1].item()
+        seq_vpreds = vpreds_values[seq_vpreds_start:seq_vpreds_end]
+        seq_vpreds = seq_vpreds.unsqueeze(0)  # [1, seq_len]
+        
+        # Get sequence length (unpadded)
+        unpadded_seq_len = seq_vpreds_end - seq_vpreds_start
+
+        # Extract data for current sequence
+        seq_data = {}
+        for key in ["values", "returns", "response_mask"]:
+            if key in data:
+                tensor = data[key]
+                if isinstance(tensor, torch.Tensor):
+                    # Handle nested tensor
+                    if hasattr(tensor, "is_nested") and tensor.is_nested:
+                        tensor_offsets = tensor.offsets()
+                        tensor_values = tensor.values()
+                        tensor_start = tensor_offsets[seq_idx].item()
+                        tensor_end = tensor_offsets[seq_idx + 1].item()
+                        seq_tensor = tensor_values[tensor_start:tensor_end].unsqueeze(0)
+                        seq_data[key] = seq_tensor
+                    # Handle regular tensor
+                    elif tensor.ndim > 1 and tensor.shape[1] > 1:
+                        # Slice to sequence length
+                        seq_data[key] = tensor[seq_idx:seq_idx+1, :unpadded_seq_len]
+                    else:
+                        seq_data[key] = tensor[seq_idx:seq_idx+1]
+                else:
+                    seq_data[key] = tensor
+
+        # Create model_output for current sequence
+        seq_model_output = {"values": seq_vpreds}
+
+        # Create TensorDict for current sequence
+        seq_data_dict = TensorDict(seq_data, batch_size=[1])
+        # Copy non-tensor metadata
+        for key in data.keys():
+            if key not in seq_data and not isinstance(data[key], torch.Tensor):
+                tu.assign_non_tensor(seq_data_dict, key, tu.get_non_tensor_data(data, key))
+
+        # Compute loss for current sequence using standard function
+        seq_loss, seq_metrics = _value_loss_standard(
+            config, seq_model_output, seq_data_dict, dp_group
+        )
+
+        # Accumulate loss and metrics
+        loss_accum += seq_loss
+        for k, v in seq_metrics.items():
+            if k not in metrics_accum:
+                metrics_accum[k] = 0.0
+            if isinstance(v, (int, float)):
+                metrics_accum[k] += v
+            elif isinstance(v, torch.Tensor):
+                metrics_accum[k] += v.detach().item() if v.numel() == 1 else v.detach()
+            else:
+                metrics_accum[k] += v
+    
+    return loss_accum, metrics_accum
+
+
+def _ppo_loss_standard(config: ActorConfig, model_output, data: TensorDict, dp_group=None):
+    # Get rank info for logging
+    try:
+        global_rank = torch.distributed.get_rank() if torch.distributed.is_initialized() else -1
+    except Exception:
+        global_rank = -1
+    
+    log_prob = model_output["log_probs"]
     log_prob = no_padding_2_padding(log_prob, data)  # (bsz, response_length)
+    entropy = model_output.get("entropy", None)
     if entropy is not None:
         entropy = no_padding_2_padding(entropy, data)  # (bsz, response_length)
 
@@ -108,31 +355,117 @@ def ppo_loss(config: ActorConfig, model_output, data: TensorDict, dp_group=None)
     return policy_loss, metrics
 
 
-def value_loss(config: CriticConfig, model_output, data: TensorDict, dp_group=None):
-    vpreds = model_output["values"]
-    vpreds = no_padding_2_padding(vpreds, data)  # (bsz, response_length)
+def _ppo_loss_with_sequence_packing(config: ActorConfig, model_output, data: TensorDict, dp_group=None, packed_seq_params=None):
+    """
+    Compute PPO loss with sequence packing support.
+    This function processes each sequence individually to avoid padding effects.
+    
+    Args:
+        config: ActorConfig
+        model_output: Dict containing "log_probs" and optionally "entropy" (nested tensors)
+        data: TensorDict containing old_log_probs, advantages, response_mask, etc.
+        dp_group: Data parallel group (optional)
+        packed_seq_params: PackedSeqParams object containing sequence boundary information
+    
+    Returns:
+        policy_loss: Accumulated policy loss across all sequences
+        metrics: Accumulated metrics dictionary
+    """
+    log_prob = model_output["log_probs"]
+    entropy = model_output.get("entropy", None)
+    
+    # Get rank info for logging
+    try:
+        global_rank = torch.distributed.get_rank() if torch.distributed.is_initialized() else -1
+    except Exception:
+        global_rank = -1
+    
+    # Check if log_prob is a nested tensor
+    if not (hasattr(log_prob, "is_nested") and log_prob.is_nested):
+        # If not nested tensor, fall back to standard loss
+        msg = f"[PPO Loss] Warning: log_prob is not a nested tensor, falling back to standard loss (rank={global_rank})"
+        logger.warning(msg)
+        print_rank_0(msg)
+        return _ppo_loss_standard(config, model_output, data, dp_group)
+    
+    # Get sequence boundaries from nested tensor
+    log_prob_offsets = log_prob.offsets()  # cu_seqlens
+    log_prob_values = log_prob.values()    # [total_tokens]
+    num_sequences = len(log_prob_offsets) - 1
+    
+    loss_accum = 0.0
+    metrics_accum = {}
 
-    values = data["values"]
-    returns = data["returns"]
-    response_mask = data["response_mask"].to(bool)
+    # Process each sequence individually
+    for seq_idx in range(num_sequences):
+        # Get log_prob for current sequence
+        seq_log_prob_start = log_prob_offsets[seq_idx].item()
+        seq_log_prob_end = log_prob_offsets[seq_idx + 1].item()
+        seq_log_prob = log_prob_values[seq_log_prob_start:seq_log_prob_end]
+        seq_log_prob = seq_log_prob.unsqueeze(0)  # [1, seq_len]
+        
+        # Get sequence length (unpadded)
+        unpadded_seq_len = seq_log_prob_end - seq_log_prob_start
 
-    vf_loss, vf_clipfrac = compute_value_loss(
-        vpreds=vpreds,
-        values=values,
-        returns=returns,
-        response_mask=response_mask,
-        cliprange_value=config.cliprange_value,
-        loss_agg_mode=config.loss_agg_mode,
-    )
+        # Extract data for current sequence
+        seq_data = {}
+        for key in ["old_log_probs", "advantages", "response_mask", "ref_log_prob"]:
+            if key in data:
+                tensor = data[key]
+                if isinstance(tensor, torch.Tensor):
+                    # Handle nested tensor
+                    if hasattr(tensor, "is_nested") and tensor.is_nested:
+                        tensor_offsets = tensor.offsets()
+                        tensor_values = tensor.values()
+                        tensor_start = tensor_offsets[seq_idx].item()
+                        tensor_end = tensor_offsets[seq_idx + 1].item()
+                        seq_tensor = tensor_values[tensor_start:tensor_end].unsqueeze(0)
+                        seq_data[key] = seq_tensor
+                    # Handle regular tensor
+                    elif tensor.ndim > 1 and tensor.shape[1] > 1:
+                        # Slice to sequence length
+                        seq_data[key] = tensor[seq_idx:seq_idx+1, :unpadded_seq_len]
+                    else:
+                        seq_data[key] = tensor[seq_idx:seq_idx+1]
+                else:
+                    seq_data[key] = tensor
 
-    metrics = {}
+        # Create model_output for current sequence
+        seq_model_output = {"log_probs": seq_log_prob}
+        if entropy is not None:
+            if hasattr(entropy, "is_nested") and entropy.is_nested:
+                entropy_offsets = entropy.offsets()
+                entropy_values = entropy.values()
+                entropy_start = entropy_offsets[seq_idx].item()
+                entropy_end = entropy_offsets[seq_idx + 1].item()
+                seq_entropy = entropy_values[entropy_start:entropy_end].unsqueeze(0)
+            else:
+                # Fallback: slice regular tensor
+                seq_entropy = entropy[seq_idx:seq_idx+1, :unpadded_seq_len]
+            seq_model_output["entropy"] = seq_entropy
 
-    metrics.update(
-        {
-            "critic/vf_loss": vf_loss.detach().item(),
-            "critic/vf_clipfrac": vf_clipfrac.detach().item(),
-            "critic/vpred_mean": masked_mean(vpreds, response_mask).detach().item(),
-        }
-    )
+        # Create TensorDict for current sequence
+        seq_data_dict = TensorDict(seq_data, batch_size=[1])
+        # Copy non-tensor metadata
+        for key in data.keys():
+            if key not in seq_data and not isinstance(data[key], torch.Tensor):
+                tu.assign_non_tensor(seq_data_dict, key, tu.get_non_tensor_data(data, key))
 
-    return vf_loss, metrics
+        # Compute loss for current sequence using standard function
+        seq_loss, seq_metrics = _ppo_loss_standard(
+            config, seq_model_output, seq_data_dict, dp_group
+        )
+
+        # Accumulate loss and metrics
+        loss_accum += seq_loss
+        for k, v in seq_metrics.items():
+            if k not in metrics_accum:
+                metrics_accum[k] = 0.0
+            if isinstance(v, (int, float)):
+                metrics_accum[k] += v
+            elif isinstance(v, torch.Tensor):
+                metrics_accum[k] += v.detach().item() if v.numel() == 1 else v.detach()
+            else:
+                metrics_accum[k] += v
+    
+    return loss_accum, metrics_accum
\ No newline at end of file
